# -*- coding: utf-8 -*-
"""CS471_A#5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zld0WClXaJZQv0uGAwtjj6CXw4UpaJLN
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import math

training_data = pd.read_csv("training.csv", header=None, usecols=[19,23], names=['Time','Current'])
test_data = pd.read_csv("test.csv", header=None, usecols=[0, 4], names=['Time','Current'])

training_data = training_data[training_data['Time'] <= 5.4]
test_data = test_data[test_data['Time'] <= 2.4]

import matplotlib.pyplot as plt

df = training_data
fault_start = 5.1
fault_end = 5.4
# Separate the data points
fault_data = df[(df['Time'] >= fault_start) & (df['Time'] <= fault_end)]
normal_data = df[(df['Time'] < fault_start) | (df['Time'] > fault_end)]

# plt.figure(figsize=(10, 2))

# # Plotting for column D
# plt.scatter(normal_data['Time'], normal_data['Current'], c='blue', label='Normal Operation (D)', alpha=0.5)
# plt.scatter(fault_data['Time'], fault_data['Current'], c='red', label='Fault (D)', alpha=0.5)


# plt.title('Scatter Plot of Current Over Time')
# plt.xlabel('Time (s)')
# plt.ylabel('Values')
# plt.legend()
# plt.grid(True)
# plt.show()

import matplotlib.pyplot as plt

df = test_data
fault_start = 2.1
fault_end = 2.4
# Separate the data points
fault_data = df[(df['Time'] >= fault_start) & (df['Time'] <= fault_end)]
normal_data = df[(df['Time'] < fault_start) | (df['Time'] > fault_end)]

# plt.figure(figsize=(10, 2))

# # Plotting for column D
# plt.scatter(normal_data['Time'], normal_data['Current'], c='blue', label='Normal Operation (D)', alpha=0.5)
# plt.scatter(fault_data['Time'], fault_data['Current'], c='red', label='Fault (D)', alpha=0.5)


# plt.title('Scatter Plot of Current Over Time')
# plt.xlabel('Time (s)')
# plt.ylabel('Values')
# plt.legend()
# plt.grid(True)
# plt.show()

# Define segmenting and labeling function

def segment_labeling(data, window, overlap, time1, time2):

  # Define the number of data points per segment = window size

  #index determines the start of a window
  #in each step of segmenting loop
  index = 0

  #windolap incorporates overlaping percentage
  windolap = math.floor (window * overlap)

  # Create an empty DataFrame for storing the labels
  labels_df = pd.DataFrame(columns=['label'])

  time_series = []

  while (index + window) < len(data):
      # Extract a segment of data
      segment = data.iloc[index : (index+window)]

      # Labeling based on a given time (the oscillation time is given)
      if any((time1 <= t <= time2) for t in segment['Time']):
        label = 'oscillation'
      else:
        label = 'normal'

      time_series.append(segment['Current'])

      # Append the label to the labels DataFrame
      labels_df = pd.concat([labels_df, pd.DataFrame({'label': [label]})], ignore_index=True)

      #Shifting the index forward by stride = window - windolap
      index += window - windolap

  # return lables_df as a DataFrame
  return time_series, labels_df

window = 200
overlap = 0.75

train_X, train_y = segment_labeling(training_data, window, overlap, 5.1, 5.4)
test_X, test_y = segment_labeling(test_data, window, overlap, 2.1, 2.4)

test_y.value_counts()

X_train = np.array(train_X)
X_test = np.array(test_X)

print(X_train.shape)
print(X_test.shape)

##########################################################################################################################################
# Student Code Starts Here
##########################################################################################################################################

from sklearn.svm import SVC
from sklearn.metrics import classification_report
from sklearn.model_selection import GridSearchCV

# Define the parameter grid for C and gamma for hyperparameter tuning
param_grid = {
    'C': [0.1, 1, 10, 100],  # Range of regularization parameter
    'gamma': [0.001, 0.01, 0.1, 1]  # Range of gamma values
}

# Initialize the SVM model with kernel type 'rbf' and class_weight 'balanced'
svc = SVC(kernel='rbf', class_weight='balanced')

# Set up GridSearchCV with cross-validation
grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', return_train_score=True)

# Fit grid_search with the training 
# train_y is raveled to correct warning about 1D array expected
grid_search.fit(X_train, train_y.values.ravel())

# Use grid_search to determine the best parameters
best_params = grid_search.best_params_
print("Best parameters found: ", best_params)

# Extract results from GridSearchCV for plotting
results = pd.DataFrame(grid_search.cv_results_)

# Plot the results of hyperparameter tuning
plt.figure(figsize=(10, 6))
for gamma_val in param_grid['gamma']:
    subset = results[results['param_gamma'] == gamma_val]
    plt.plot(subset['param_C'], subset['mean_test_score'], label=f'gamma={gamma_val}')

plt.xscale('log')
plt.xlabel('C (Regularization Parameter)')
plt.ylabel('Cross-Validation Accuracy')
plt.title('Hyperparameter Tuning for SVM')
plt.legend(title='Gamma')
plt.show()

# Initialize final model with optimal hyperparameters found during validation testing
final_model = SVC(kernel='rbf', class_weight='balanced', C=best_params['C'], gamma=best_params['gamma'])

# Train final model on entire training dataset
# train_y is raveled to correct warning about 1D array expected
final_model.fit(X_train, train_y.values.ravel())

# Evaluate the test set
y_pred = final_model.predict(X_test)

# Print classification report
print("Classification Report on Test Set:")
print(classification_report(test_y, y_pred))